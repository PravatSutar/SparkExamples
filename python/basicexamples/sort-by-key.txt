# cat data.txt
crazy crazy fox jumped
crazy fox jumped
fox is fast
fox is smart
dog is smart

# ./bin/pyspark
Python 2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03)
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
Anaconda is brought to you by Continuum Analytics.
Please check out: http://continuum.io/thanks and https://binstar.org
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 1.3.1
      /_/

Using Python version 2.7.10 (default, May 28 2015 17:02:03)
SparkContext available as sc, HiveContext available as sqlContext.

>>>
>>> lines = sc.textFile('data.txt', 1);
>>> lines.collect()
[
 u'crazy crazy fox jumped', 
 u'crazy fox jumped', 
 u'fox is fast', 
 u'fox is smart', 
 u'dog is smart'
]

>>> frequencies = lines.flatMap(lambda x: x.split(' ')).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)
>>> frequencies.collect()
[
 (u'crazy', 3), 
 (u'jumped', 2), 
 (u'is', 3), 
 (u'fox', 4), 
 (u'dog', 1), 
 (u'fast', 1), 
 (u'smart', 2)
]

>>> frequencies.count()
7

>>> sorted = frequencies.sortByKey()
>>> sorted.collect()
[
 (u'crazy', 3), 
 (u'dog', 1), 
 (u'fast', 1), 
 (u'fox', 4), 
 (u'is', 3), 
 (u'jumped', 2), 
 (u'smart', 2)
]
>>>
>>> sortedDescending = frequencies.sortByKey(False)
>>> sortedDescending.collect()
[
 (u'smart', 2), 
 (u'jumped', 2), 
 (u'is', 3), 
 (u'fox', 4), 
 (u'fast', 1), 
 (u'dog', 1), 
 (u'crazy', 3)
]
