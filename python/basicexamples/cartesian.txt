# ./pyspark
Python 2.7.10 |Anaconda 2.3.0 (64-bit)| (default, May 28 2015, 17:02:03)
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
Anaconda is brought to you by Continuum Analytics.
Please check out: http://continuum.io/thanks and https://binstar.org
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 1.3.1
      /_/

Using Python version 2.7.10 (default, May 28 2015 17:02:03)
SparkContext available as sc, HiveContext available as sqlContext.

>>> a = [('k1','v1'), ('k2', 'v2')]
>>> a
[('k1', 'v1'), ('k2', 'v2')]
>>> b = [('k3','v3'), ('k4', 'v4'), ('k5', 'v5') ]
>>> b
[('k3', 'v3'), ('k4', 'v4'), ('k5', 'v5')]
>>> rdd1= sc.parallelize(a)
>>> rdd1.collect()
[('k1', 'v1'), ('k2', 'v2')]
>>> rdd2= sc.parallelize(b)
>>> rdd2.collect()
[('k3', 'v3'), ('k4', 'v4'), ('k5', 'v5')]
>>> rdd3 = rdd1.cartesian(rdd2)
>>> rdd3.collect()
[
 (('k1', 'v1'), ('k3', 'v3')), 
 (('k1', 'v1'), ('k4', 'v4')), 
 (('k1', 'v1'), ('k5', 'v5')), 
 (('k2', 'v2'), ('k3', 'v3')), 
 (('k2', 'v2'), ('k4', 'v4')), 
 (('k2', 'v2'), ('k5', 'v5'))
]
>>>
